{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13be91ad-cb72-4fd6-bd4d-f92af4eba463",
   "metadata": {},
   "source": [
    "# Baseline ST-MapMatching Algorithm Implementation\n",
    "This notebook implements the baseline ST-MapMatching algorithm which already exists in the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d95d3d-bfda-415b-8a3a-75c0f7608b03",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "1. Imports and Setup  \n",
    "2. Load Data and Processing\n",
    "3. Trajectory Sample Preparation\n",
    "4. Define Algorithm Functions  \n",
    "5. Run Map Matching  \n",
    "6. Computation of Metrics\n",
    "7. Visualization    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70640fd3-3d8f-4dcd-8f1c-d499326c3a81",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2cdd5-9199-4f2b-be70-196c52c82053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for ST-MapMatching algorithm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from osmnx import graph_from_place, save_graphml, load_graphml\n",
    "from shapely.ops import nearest_points, unary_union, linemerge, substring, polygonize\n",
    "from shapely.geometry import LineString, MultiLineString, Point\n",
    "from scipy.spatial.distance import cosine\n",
    "from copy import deepcopy\n",
    "from math import sqrt, pi\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cc243-0b96-4b9d-a0ea-90de3c504f14",
   "metadata": {},
   "source": [
    "## 2. Load Data and Processing\n",
    "\n",
    "### Reading Trajectory Data\n",
    "\n",
    "- Read trajectory data from CSV file.\n",
    "- Convert trajectory DataFrame into a GeoDataFrame by creating shapely `Point` geometries\n",
    "  from the longitude and latitude columns.\n",
    "- Assign the coordinate reference system (CRS) as EPSG:4326 (WGS84).\n",
    "- Convert velocity units from meters per second to kilometers per hour for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4917f-6323-4b51-bc61-269283bae938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the trajectory data\n",
    "traj = pd.read_csv(\"car_traj_HF.csv\")\n",
    "\n",
    "# Turning the traj Dataframe into a GeoDataFrame using the Longitude and Latitude columns as Shapely points geometry and assigning the CRS\n",
    "points = traj.apply(lambda row: Point(row.Longitude, row.Latitude), axis=1)\n",
    "traj = gpd.GeoDataFrame(traj, geometry=points)\n",
    "traj.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee0fbf-311d-4ba7-a00f-ad5347c6c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7636e-2d86-4a4f-9bc4-d188e4c20513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the unit of Velocity from [m/s] to [km/h] to use later in the algorithm functions:\n",
    "traj['Velocity'] = traj['Velocity'] * 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f26e8-e1f5-4217-a1c9-f65edbd5785f",
   "metadata": {},
   "source": [
    "### Reading Network Data\n",
    "\n",
    "- Load nodes and edges layers from a GeoPackage file representing Milan's drivable street network.\n",
    "- Drop columns from nodes and edges that are not needed for the analysis to reduce memory and clutter.\n",
    "- Preview the edges data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a837dc8-dfe6-4a22-9964-853a9e694cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the network data of the graph of drivable streets of Milan urban area from a Geopackage file with two layers of nodes and edges\n",
    "nodes_drive = gpd.read_file(\"myMilan_drive.gpkg\", layer=\"nodes\")\n",
    "edges_drive = gpd.read_file(\"myMilan_drive.gpkg\", layer=\"edges\")\n",
    "\n",
    "# Removing some of the columns that are never used later\n",
    "edges_drive.drop(columns=['junction', 'ref', 'bridge', 'tunnel', 'width', 'access', 'est_width'], inplace=True)\n",
    "nodes_drive.drop(columns=['highway', 'ref', 'junction', 'railway', 'street_count', 'closeness', 'closeness_weighted', 'betweenness', \n",
    "                         'betweenness_weighted'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec0d82-9edc-497e-bf7f-fff6fbe72d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_drive.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e85a4-9fc6-4c52-bd24-192f3b30aa0c",
   "metadata": {},
   "source": [
    "### Loading the Graph Object\n",
    "\n",
    "- Load the drivable street network graph from a GraphML file (retrieved previously from OpenStreetMap).\n",
    "- This gives a `networkx.MultiDiGraph` object used for spatial analysis.\n",
    "- Add a `geometry` attribute to each node by converting 'x' and 'y' coordinate attributes into shapely Point objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802fd24-40b7-4348-90b4-67f1019f0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give us a networkx MultiDiGraph that we use later for the analysis\n",
    "milan_drive = load_graphml(\"milan_drive.graphml\")\n",
    "\n",
    "# Add a 'geometry' attribute to each node using its 'x' and 'y' coordinates\n",
    "# This converts node positions into shapely Point objects for spatial analysis\n",
    "for node, data in milan_drive.nodes(data=True):\n",
    "    if 'x' in data and 'y' in data:\n",
    "        data['geometry'] = Point(data['x'], data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19eaa2-2922-42e3-88ba-73b3fc04dc61",
   "metadata": {},
   "source": [
    "## 3. Trajectory Sample Preparation\n",
    "\n",
    "In this section, we sample a single trajectory to test the ST-MapMatching algorithm on a manageable subset first.\n",
    "We also define a spatial buffer around sample points and adjust coordinate reference systems (CRS) for accurate spatial calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536201b-2c78-489c-bbf8-ec74c16d9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a trajectory for testing: \n",
    "# Change sample_number to select a different trajectory sample from the dataset\n",
    "sample_number = 0  \n",
    "sample = traj[traj[\"Traj_ID\"] == traj['Traj_ID'].unique()[sample_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e5160-d8a9-4b87-9070-46c92b3c9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the buffer distance around points (meters) and standard deviation used in observation probability\n",
    "# Based on Lou et al. 2009, buffer is 100m with std dev 20, but we use 50m buffer to reduce computation time\n",
    "point_buffer = 50 \n",
    "standard_deviation = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a7bf5-190d-4920-aad6-2deb65c90571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert sample points to projected CRS (EPSG:6707) for accurate distance measurements\n",
    "sample = sample.to_crs(epsg=6707)\n",
    "# Create a buffer circle of size point_buffer (in meters) around each sample point\n",
    "sample['small_buffer'] = sample.buffer(point_buffer)\n",
    "# visualizing the sample poitns with the buffer around them\n",
    "sample['small_buffer'].explore(tiles=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2655e8d-37d2-4c62-80ba-8b9f8de583fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change network data CRS to projected coordinate system (EPSG:6707)\n",
    "# to align with sample trajectory data for spatial analysis\n",
    "edges_drive = edges_drive.to_crs(epsg=6707)\n",
    "nodes_drive = nodes_drive.to_crs(epsg=6707)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06019789-a9d6-4ad6-8560-b3e2cc45e511",
   "metadata": {},
   "source": [
    "### ---------------------------------------Now the Sample is ready--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ccc79-11cf-44f0-8cfc-e6af2d429716",
   "metadata": {},
   "source": [
    "## 4. Define Algorithm Functions\n",
    "\n",
    "The following cells contains all the functions used in the ST-MapMatching algorithm.\n",
    "\n",
    "### Score Matrix Structure\n",
    "\n",
    "The score matrix is a 3D structure defined as:<br>\n",
    "<em>score_matrix$[i][j][k] = score$<br>\n",
    "\n",
    "- `i`: index of the current GPS point $P_i$\n",
    "- `j`: index of the candidate for point `i-1`\n",
    "- `k`: index of the candidate for point `i`\n",
    "- `score` is the combined $observation$ and $transmission$ probability for this transition: $c_{i-1}^j \\rightarrow c_{i}^k$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84659ad0-1f84-4bc0-bffe-c9907053c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================== Candidate points selection functions ===============================+\n",
    "\n",
    "def get_candidate_points(gps_point, edges_gdf, buffer_radius=point_buffer):\n",
    "    \"\"\"\n",
    "    Given a GPS point, return candidate road segments with projected points.\n",
    "\n",
    "    Parameters:\n",
    "    - gps_point: shapely Point (e.g., row['geometry'] from GPS data)\n",
    "    - edges_gdf: GeoDataFrame of road segments (edges_drive)\n",
    "    - buffer_radius: in meters\n",
    "\n",
    "    Returns:\n",
    "    - List of dicts with candidate data\n",
    "    \"\"\"\n",
    "    # Create buffer around the GPS point\n",
    "    buffer = gps_point.buffer(buffer_radius)\n",
    "\n",
    "    # Filter edges that intersect with the buffer\n",
    "    nearby_edges = edges_gdf[edges_gdf.intersects(buffer)]\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    for _, edge in nearby_edges.iterrows():\n",
    "        # Project GPS point onto edge line\n",
    "        projected_point = edge['geometry'].interpolate(\n",
    "            edge['geometry'].project(gps_point)\n",
    "        )\n",
    "        dist = gps_point.distance(projected_point)\n",
    "        # for each candidate the following features are saved in a dict:\n",
    "        candidate = {\n",
    "            'edge_osmid': edge['osmid'],\n",
    "            'projected_point': projected_point,\n",
    "            'distance': dist,\n",
    "            'edge_geometry': edge['geometry'],\n",
    "            'speed_limit': edge['speed_limit'],\n",
    "            'u': edge['u'],\n",
    "            'v': edge['v'],\n",
    "            'key': edge['key']\n",
    "        }\n",
    "\n",
    "        candidates.append(candidate)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "# -------------------------------------------------------------------------------------------+\n",
    "\n",
    "def get_all_candidates(sample):\n",
    "    \"\"\"\n",
    "    Loops through sample dataframe and runs get_candidate_points() on every gps point\n",
    "\n",
    "    Parametes:\n",
    "    -sample: dataframe of a sample trajectory \n",
    "\n",
    "    Returns:\n",
    "    -List of lists of dicts\n",
    "    \"\"\"\n",
    "    all_candidates = []  # This will be a list of lists — one list per GPS point\n",
    "\n",
    "    for idx, row in sample.iterrows():\n",
    "        gps_point = row.geometry\n",
    "        candidates = get_candidate_points(gps_point, edges_drive, buffer_radius=point_buffer)\n",
    "        all_candidates.append(candidates)\n",
    "    return all_candidates    \n",
    "\n",
    "# ====================================Observation Probability Function ===============================================+\n",
    "\n",
    "def add_observation_probability(all_candidates, sigma=standard_deviation):\n",
    "    \"\"\"\n",
    "    Computes the observation probability based on distance using a Gaussian model and adds it to the candidate dicts.\n",
    "    It uses the constant standard deviation value defined previously (sigma = 20)\n",
    "\n",
    "    Parameters:\n",
    "    - all_candidates: the list of the candidate points\n",
    "    - sigma: the standard deviation in the observation probability formula\n",
    "    \n",
    "    Returns:\n",
    "    - doesn't return anything. Just modifies the input list of dictionaries\n",
    "    \"\"\"\n",
    "    for candidate_list in all_candidates:\n",
    "        for candidate in candidate_list:\n",
    "            distance = candidate['distance']\n",
    "            candidate['obs_prob'] = (1 / (sqrt(2 * pi) * sigma)) * np.exp(- (distance ** 2) / (2 * sigma ** 2))        \n",
    "\n",
    "# =============================== Graph Manipulation Functions ============================================+\n",
    "\n",
    "# -------------------------- Node Insertion Function -----------------------------------------+\n",
    "def insert_virtual_node_directed(G, u, v, line_geom, projected_point, node_id):\n",
    "    \"\"\"\n",
    "    Insert a virtual node along a directed edge (u, v) in graph G, splitting the edge into two segments.\n",
    "\n",
    "    This function preserves all edge attributes and handles cases where the edge has\n",
    "    been previously split. If other virtual nodes exist on the same edge, it connects\n",
    "    them with shortcut edges to maintain graph connectivity.\n",
    "\n",
    "    Parameters:\n",
    "       - G (networkx.DiGraph): The graph containing the edge (u, v).\n",
    "       - u (node): Source node of the edge.\n",
    "       - v (node): Target node of the edge.\n",
    "       - line_geom (shapely.geometry.LineString): Geometry of the original edge.\n",
    "       - projected_point (shapely.geometry.Point): The point where the virtual node is inserted.\n",
    "       - node_id (hashable): Identifier for the new virtual node.\n",
    "\n",
    "    Returns:\n",
    "        networkx.DiGraph: The updated graph with the virtual node and new edges inserted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try to reconstruct geometry if edge (u, v) was already split\n",
    "    if not G.has_edge(u, v):\n",
    "        for nbr in G.successors(u):\n",
    "            if isinstance(nbr, tuple) and G.has_edge(nbr, v):\n",
    "                geom_u = G.nodes[u].get('geometry')\n",
    "                geom_nbr = G.nodes[nbr].get('geometry')\n",
    "                geom_v = G.nodes[v].get('geometry')\n",
    "\n",
    "                if geom_u and geom_nbr and geom_v:\n",
    "                    line_geom = LineString([geom_u, geom_nbr, geom_v])\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"⚠️ Can't reconstruct geometry for edge ({u}, {v}) — missing node geometries.\")\n",
    "            return G\n",
    "\n",
    "    # Interpolate projection point\n",
    "    distance_on_line = line_geom.project(projected_point)\n",
    "    point_on_line = line_geom.interpolate(distance_on_line)\n",
    "\n",
    "    # Split original line at the projected point\n",
    "    segment1 = LineString([line_geom.coords[0], (point_on_line.x, point_on_line.y)])\n",
    "    segment2 = LineString([(point_on_line.x, point_on_line.y), line_geom.coords[-1]])\n",
    "\n",
    "    length1 = segment1.length\n",
    "    if length1 < 1e-6:\n",
    "        length1 = 1.0  # minimum length 1 meter\n",
    "\n",
    "    length2 = segment2.length\n",
    "    if length2 < 1e-6:\n",
    "        length2 = 1.0  # minimum length 1 meter    \n",
    "\n",
    "    # Safely extract attributes and avoid duplicate 'length'\n",
    "    attrs = G.get_edge_data(u, v) or {}\n",
    "    if 0 in attrs:  # If it's a MultiDiGraph with multiedges\n",
    "        attrs = attrs[0]\n",
    "    attrs = {k: v for k, v in attrs.items() if k != 'length'}\n",
    "\n",
    "    # Remove original edge if it exists\n",
    "    if G.has_edge(u, v):\n",
    "        G.remove_edge(u, v)\n",
    "\n",
    "    # Insert virtual node and new split edges\n",
    "    G.add_node(node_id, geometry=projected_point)\n",
    "    G.add_edge(u, node_id, length=segment1.length, **attrs)\n",
    "    G.add_edge(node_id, v, length=segment2.length, **attrs)\n",
    "\n",
    "    # Connect to any other virtual node already inserted on this edge\n",
    "    for nbr in list(G.successors(u)):\n",
    "        if isinstance(nbr, tuple) and nbr != node_id and G.has_edge(nbr, v):\n",
    "            p1 = G.nodes[nbr]['geometry']\n",
    "            p2 = projected_point\n",
    "            dist = p1.distance(p2)\n",
    "            if dist == 0:\n",
    "                dist = 1 #handling cases where the points are super close\n",
    "            G.add_edge(nbr, node_id, length=dist, is_virtual=True)\n",
    "            G.add_edge(node_id, nbr, length=dist, is_virtual=True)\n",
    "\n",
    "    return G\n",
    "\n",
    "# ---------------------------- Euclidean Heuristic Function to use in A* algorithm ----------------------------+\n",
    "\n",
    "def euclidean_heuristic(a, b, G):\n",
    "    \"\"\"\n",
    "    Compute the straight-line (Euclidean) distance between two nodes in graph G.\n",
    "\n",
    "    Parameters:\n",
    "        a (node): The first node identifier.\n",
    "        b (node): The second node identifier.\n",
    "        G (networkx.Graph): The graph containing node geometries.\n",
    "\n",
    "    Returns:\n",
    "        float: Euclidean distance between the geometries of nodes a and b.\n",
    "               Returns 0 if geometry is missing for either node.\n",
    "    \"\"\"\n",
    "    geom_a = G.nodes[a].get('geometry')\n",
    "    geom_b = G.nodes[b].get('geometry')\n",
    "    if geom_a and geom_b:\n",
    "        return geom_a.distance(geom_b)\n",
    "    return 0\n",
    "\n",
    "# --------------- Function to run A* algorithm to find the shortest path and its length \n",
    "\n",
    "def compute_network_distance_with_path(cand1, cand2, base_graph):\n",
    "    \"\"\"\n",
    "    Compute the shortest network distance and corresponding edge path between two candidate points.\n",
    "\n",
    "    This function inserts virtual nodes at the projected points of two candidates on the base graph,\n",
    "    then runs A* shortest path search between these virtual nodes using a Euclidean heuristic.\n",
    "    It returns both the shortest path length and the sequence of edges (with keys) along the path.\n",
    "\n",
    "    Parameters:\n",
    "        - cand1 (dict): Candidate point dictionary containing 'u', 'v', 'edge_geometry', and 'projected_point'.\n",
    "        - cand2 (dict): Another candidate point dictionary with the same keys as cand1.\n",
    "        - base_graph (networkx.DiGraph): The directed graph representing the road network.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            float: The shortest path distance between the two candidates (or infinity if no path exists).\n",
    "            list of tuples: The edge path as a list of (u, v, key) tuples representing edges along the shortest path.\n",
    "    \"\"\"\n",
    "\n",
    "    G = deepcopy(base_graph)\n",
    "    id1 = ('virtual', 'A')\n",
    "    id2 = ('virtual', 'B')\n",
    "\n",
    "    try:\n",
    "        G = insert_virtual_node_directed(G, cand1['u'], cand1['v'], cand1['edge_geometry'], cand1['projected_point'], id1)\n",
    "        G = insert_virtual_node_directed(G, cand2['u'], cand2['v'], cand2['edge_geometry'], cand2['projected_point'], id2)\n",
    "       \n",
    "        # Running A* algorithm to find the shortest path between two nodes on the graph\n",
    "        path = nx.astar_path(\n",
    "            G, source=id1, target=id2,\n",
    "            heuristic=lambda a, b: euclidean_heuristic(a, b, G),\n",
    "            weight='length'\n",
    "        )\n",
    "        distance = nx.path_weight(G, path, weight='length')\n",
    "\n",
    "        # Convert to enriched edge path\n",
    "        enriched_edge_path = []\n",
    "        for u, v in zip(path[:-1], path[1:]):\n",
    "            data = G.get_edge_data(u, v, default={})\n",
    "            key = min(data.keys()) if isinstance(data, dict) else 0\n",
    "            edge_attrs = data.get(key, {}) if isinstance(data, dict) else data\n",
    "\n",
    "            length = edge_attrs.get('length', 0.0)\n",
    "\n",
    "            enriched_edge_path.append((u, v, key, length))\n",
    "\n",
    "        return distance, enriched_edge_path\n",
    "\n",
    "    except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "        return float('inf'), []\n",
    "\n",
    "# ===================== Score Matrix Construction Funcions =================================+\n",
    "\n",
    "# ------------------------ Spatial Score Function ------------------------------------------+\n",
    "\n",
    "def build_spatial_score_matrix(all_candidates, sample, base_graph, verbose=False):\n",
    "    \"\"\"\n",
    "    Computes the spatial score matrix (obs × trans) and saves edge paths for temporal analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - all_candidates: list of candidate lists for each GPS point\n",
    "    - sample: GeoDataFrame of the GPS trajectory (must include 'Delta_d')\n",
    "    - base_graph: NetworkX DiGraph of road network\n",
    "    - verbose: if True, prints debug info\n",
    "\n",
    "    Returns:\n",
    "    - score_matrix: nested dict [i][j][k] = obs × trans\n",
    "    - edge_path_matrix: nested dict [i][j][k] = list of (u, v, key) edges\n",
    "    \"\"\"\n",
    "    score_matrix = {}\n",
    "    edge_path_matrix = {}\n",
    "\n",
    "    for i in range(1, len(sample)):\n",
    "        score_matrix[i] = {}\n",
    "        edge_path_matrix[i] = {}\n",
    "\n",
    "        gps_dist = sample.iloc[i].Delta_d\n",
    "\n",
    "        for j, cand_prev in enumerate(all_candidates[i - 1]):\n",
    "            score_matrix[i][j] = {}\n",
    "            edge_path_matrix[i][j] = {}\n",
    "\n",
    "            for k, cand_curr in enumerate(all_candidates[i]):\n",
    "                obs_prob = cand_curr.get('obs_prob', 0)\n",
    "\n",
    "                # Compute network distance and edge path\n",
    "                net_dist, edge_path = compute_network_distance_with_path(cand_prev, cand_curr, base_graph)\n",
    "\n",
    "                trans_prob = gps_dist / net_dist if net_dist not in [0, float('inf')] else 0.0\n",
    "                score = obs_prob * trans_prob\n",
    "\n",
    "                # Optional logging\n",
    "                if verbose:\n",
    "                    print(f'Trying: P{i-1} cand {j} → P{i} cand {k}   | '\n",
    "                          f'net_dist = {net_dist:.2f}   | gps_dist = {gps_dist:.2f}   | '\n",
    "                          f'obs = {obs_prob:.6f}   | trans = {trans_prob:.6f}   | score = {score:.6f}')\n",
    "\n",
    "                # Save both score and edge path\n",
    "                score_matrix[i][j][k] = score\n",
    "                edge_path_matrix[i][j][k] = edge_path\n",
    "\n",
    "    return score_matrix, edge_path_matrix\n",
    "\n",
    "# ------------------------- Temporal Score Function ------------------------------------------------+ \n",
    "\n",
    "def build_temporal_matrix(sample, edge_path_matrix, all_candidates, edges_drive, verbose=False):\n",
    "    \"\"\"\n",
    "    Build the temporal similarity matrix based on the cosine similarity between \n",
    "    actual GPS speeds and expected speeds from matched road segments.\n",
    "\n",
    "    The matrix compares each candidate transition’s expected speed profile \n",
    "    to the observed speed, accounting for virtual edges and real road segments.\n",
    "\n",
    "    Parameters:\n",
    "        - sample (GeoDataFrame): GPS trajectory data with a 'Velocity' column.\n",
    "        - edge_path_matrix (dict): Nested dictionary containing edge paths between candidate points.\n",
    "        - all_candidates (list): List of candidate points for each GPS point.\n",
    "        - edges_drive (GeoDataFrame): Road network edges containing speed limit information.\n",
    "        - verbose (bool): If True, prints detailed debug information.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dictionary temporal_matrix[i][j][k] with cosine similarity scores \n",
    "              representing temporal similarity between candidates j and k at points i-1 and i.\n",
    "    \"\"\"\n",
    "    temporal_matrix = {}\n",
    "\n",
    "    for i in range(1, len(sample)):\n",
    "        t_actual = sample.iloc[i].Delta_t\n",
    "        v_actual = 0\n",
    "        temporal_matrix[i] = {}\n",
    "\n",
    "        for j in range(len(all_candidates[i - 1])):\n",
    "            temporal_matrix[i][j] = {}\n",
    "\n",
    "            for k in range(len(all_candidates[i])):\n",
    "                edge_path = edge_path_matrix[i][j][k]\n",
    "                l_shortest = sum(length for _, _, _, length in edge_path)\n",
    "\n",
    "                if not edge_path or l_shortest < 1.0 or t_actual <= 0:\n",
    "                    sim = 0.0\n",
    "                    temporal_matrix[i][j][k] = sim\n",
    "                    if verbose:\n",
    "                        print(f\"⚠️ Skipping temporal score at i={i}, j={j}, k={k} — l_shortest={l_shortest:.2f}, t_actual={t_actual}\")\n",
    "                    continue  # skip to next candidate pair\n",
    "                else:\n",
    "                    v_actual = (l_shortest / t_actual) * 3.6 \n",
    "\n",
    "                expected_speeds = []\n",
    "\n",
    "                # Include entry (from previous candidate)\n",
    "                entry_speed = all_candidates[i - 1][j].get('speed_limit', None)\n",
    "                if entry_speed is not None:\n",
    "                    expected_speeds.append(entry_speed)\n",
    "\n",
    "                # Internal edges (skip virtual ones)\n",
    "                for u, v, key, length in edge_path:\n",
    "                    if isinstance(u, tuple) or isinstance(v, tuple):\n",
    "                        continue\n",
    "                    match = edges_drive[\n",
    "                        (edges_drive['u'] == u) & (edges_drive['v'] == v) & (edges_drive['key'] == key)\n",
    "                    ]\n",
    "                    if not match.empty:\n",
    "                        speed = match.iloc[0]['speed_limit']\n",
    "                        expected_speeds.append(speed)\n",
    "                    elif verbose:\n",
    "                        print(f\"⚠️  No match found for edge: u={u}, v={v}, key={key}\")\n",
    "\n",
    "                # Include exit (to next candidate)\n",
    "                exit_speed = all_candidates[i][k].get('speed_limit', None)\n",
    "                if exit_speed is not None:\n",
    "                    expected_speeds.append(exit_speed)\n",
    "\n",
    "                # Compute similarity\n",
    "                if len(expected_speeds) == 1:\n",
    "                    sim = 1.0\n",
    "                elif len(expected_speeds) == 0:\n",
    "                    sim = 0.0\n",
    "                else:\n",
    "                    actual_vector = [v_actual] * len(expected_speeds)\n",
    "                    try:\n",
    "                        sim = 1 - cosine(actual_vector, expected_speeds)\n",
    "                        if np.isnan(sim):\n",
    "                            print(f\"⚠️ NaN similarity: i={i}, j={j}, k={k}, actual={actual_vector}, expected={expected_speeds}\")\n",
    "                            sim = 0.0\n",
    "                        #sim = sim if not np.isnan(sim) else 0.0\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Error at i={i}, j={j}, k={k}: {e}\")\n",
    "                        sim = 0.0\n",
    "\n",
    "                temporal_matrix[i][j][k] = sim\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"\\n--- Temporal Score: P{i-1} cand {j} → P{i} cand {k} ---\")\n",
    "                    print(f\"• Number of edges   : {len(edge_path)}\")\n",
    "                    print(f\"• Expected speeds   : {[round(float(s), 1) for s in expected_speeds]}\")\n",
    "                    print(f\"• Actual GPS speed  : {v_actual:.2f}\")\n",
    "                    print(f\"• Cosine similarity : {sim:.4f}\")\n",
    "\n",
    "    return temporal_matrix\n",
    "\n",
    "# ============================= Candidate Graph Construction and Analysis Functions (DAG) ===========================+\n",
    "\n",
    "# -------------------------- Candidate Graph Creation Function ----------------------------+\n",
    "\n",
    "def build_candidate_graph(all_candidates, score_matrix, temporal_matrix):\n",
    "    \"\"\"\n",
    "    Builds the candidate graph as described in the ST-Matching paper.\n",
    "\n",
    "    Parameters:\n",
    "    - all_candidates (list of list of dict): Candidate points for each GPS observation.\n",
    "    - score_matrix (dict): Nested spatial score matrix indexed as [i][j][k].\n",
    "    - temporal_matrix (dict): Nested temporal similarity matrix indexed as [i][j][k].\n",
    "    \n",
    "    Returns:\n",
    "    - G: a NetworkX DiGraph representing the candidate graph\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add all candidate nodes with observation probabilities\n",
    "    for i, candidates in enumerate(all_candidates):\n",
    "        for k, cand in enumerate(candidates):\n",
    "            G.add_node((i, k), geometry=cand['projected_point'], obs_prob=cand['obs_prob'])\n",
    "\n",
    "    # Add edges between candidates of consecutive points\n",
    "    for i in range(1, len(all_candidates)):\n",
    "        for j in range(len(all_candidates[i - 1])):\n",
    "            for k in range(len(all_candidates[i])):\n",
    "                spatial_score = score_matrix[i][j][k]\n",
    "                temporal_score = temporal_matrix[i][j][k]\n",
    "                final_score = spatial_score * temporal_score\n",
    "\n",
    "                if final_score > 0:\n",
    "                    G.add_edge((i - 1, j), (i, k),\n",
    "                               score=final_score,\n",
    "                               trans_prob=spatial_score,\n",
    "                               temp_sim=temporal_score,\n",
    "                               weight=final_score)  # keep weight for networkx algorithms\n",
    "\n",
    "\n",
    "    return G\n",
    "\n",
    "# -------------------- Function to find the best path in the candidate graph based on the scores ----------------+\n",
    "\n",
    "def find_best_path(G):\n",
    "    \"\"\"\n",
    "    Finds the highest scoring path in the DAG candidate graph using topological sort + dynamic programming.\n",
    "    \n",
    "    The graph nodes represent candidate points, and edges represent transitions weighted by scores.\n",
    "    This function computes the path with the maximum cumulative score.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: candidate graph (NetworkX DiGraph)\n",
    "\n",
    "    Returns:\n",
    "    - best_path: list of node IDs (tuples like (i, k)) forming the best candidate path\n",
    "    \"\"\"\n",
    "    # Initialize score and predecessor dictionaries\n",
    "    score = {}\n",
    "    predecessor = {}\n",
    "\n",
    "    # Topological order traversal\n",
    "    topo_order = list(nx.topological_sort(G))\n",
    "\n",
    "    for node in topo_order:\n",
    "        # Get incoming edges\n",
    "        preds = G.in_edges(node, data=True)\n",
    "\n",
    "        if not preds:\n",
    "            # Start nodes: base score = obs_prob only\n",
    "            score[node] = G.nodes[node].get('obs_prob', 0.0)\n",
    "            predecessor[node] = None\n",
    "        else:\n",
    "            # Maximize over all incoming transitions\n",
    "            max_score = -float('inf')\n",
    "            best_pred = None\n",
    "            for u, v, data in preds:\n",
    "                edge_score = score.get(u, 0.0) + data['weight']\n",
    "                if edge_score > max_score:\n",
    "                    max_score = edge_score\n",
    "                    best_pred = u\n",
    "            score[node] = max_score\n",
    "            predecessor[node] = best_pred\n",
    "\n",
    "    # Backtrack from node with highest final score\n",
    "    end_node = max(score, key=score.get)\n",
    "    best_path = []\n",
    "    current = end_node\n",
    "\n",
    "    while current is not None:\n",
    "        best_path.append(current)\n",
    "        current = predecessor[current]\n",
    "\n",
    "    best_path.reverse()\n",
    "    return best_path\n",
    "\n",
    "# ---------------------------- Visualization Function of the candidate graph ------------------------------------+\n",
    "\n",
    "def plot_abstract_candidate_graph(G, best_path=None, start_layer=0, end_layer=5):\n",
    "    \"\"\"\n",
    "    Abstract visualization of the candidate graph (not map-based), showing a specific range of GPS point layers.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: candidate graph (NetworkX DiGraph)\n",
    "    - best_path: list of (i, k) tuples representing the best candidate path (optional)\n",
    "    - start_layer: starting GPS point index (inclusive)\n",
    "    - end_layer: ending GPS point index (exclusive)\n",
    "    \"\"\"\n",
    "    pos = {}  # positions for drawing\n",
    "    nodes_to_include = []\n",
    "\n",
    "    # Layout: x = point index (layer), y = candidate index\n",
    "    for (i, k) in G.nodes:\n",
    "        if start_layer <= i < end_layer:\n",
    "            pos[(i, k)] = (i, -k)  # negative k so it draws top-down\n",
    "            nodes_to_include.append((i, k))\n",
    "\n",
    "    # Subgraph for just selected layers\n",
    "    subgraph = G.subgraph(nodes_to_include)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # First: draw all edges in light gray\n",
    "    nx.draw_networkx_edges(subgraph, pos, edge_color='gray', arrows=True)\n",
    "\n",
    "    # Then: if best path is provided, draw it on top\n",
    "    if best_path is not None:\n",
    "        best_edges = list(zip(best_path[:-1], best_path[1:]))  # edges between consecutive nodes\n",
    "        nx.draw_networkx_edges(subgraph, pos,\n",
    "                               edgelist=best_edges,\n",
    "                               edge_color='#DC143C',  # Best path in RED\n",
    "                               width=2,\n",
    "                               arrows=True)\n",
    "\n",
    "    # Draw nodes and labels\n",
    "    nx.draw_networkx_nodes(subgraph, pos, node_color='skyblue', node_size=300)\n",
    "    nx.draw_networkx_labels(subgraph, pos, font_size=8)\n",
    "\n",
    "    plt.title(f\"Abstract View of Candidate Graph (P{start_layer} to P{end_layer - 1})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# ===================== Getting the Final Matched Points and Edges =========================+   \n",
    "\n",
    "def get_matched_points_and_edges(candidate_points, best_candidate_path, edge_path, edges_gdf, sample):\n",
    "    \"\"\"\n",
    "    The function returns two geodataframes of matched point and matched edges from the best candidate path\n",
    "\n",
    "    Parameters:\n",
    "    - candidate_points: list of dicts of all candidate points\n",
    "    - best_candidate_path: a list of tuples which is the output of finding the best path function\n",
    "    - edge_path: the edge path matrix\n",
    "    - edges_gdf: the geodataframe of the edges of the network\n",
    "    - sample: the geodataframe of the gps sample points\n",
    "\n",
    "    Returns:\n",
    "    two GeoDataFrames of the matched points and the path edges\n",
    "    \"\"\"\n",
    "    matched_points = [\n",
    "    candidate_points[i][k]['projected_point']\n",
    "    for (i, k) in best_candidate_path\n",
    "    ]\n",
    "    matched_points_gdf = gpd.GeoDataFrame(geometry=matched_points, crs=sample.crs)\n",
    "    \n",
    "    #edges that contain a matched point:\n",
    "    ##if two consecutive points are matched on the same edge (considering the direction), this will include that edge only once:\n",
    "    matched_edges = []\n",
    "    previous_edge = None\n",
    "\n",
    "    for (i, k) in best_candidate_path:\n",
    "        cand = candidate_points[i][k]\n",
    "        \n",
    "        current_edge = (cand['u'], cand['v'], cand['key'])\n",
    "    \n",
    "        if previous_edge != current_edge:\n",
    "            selected_edge = edges_gdf[(edges_gdf['u'] == cand['u']) & (edges_gdf['v'] == cand['v']) & (edges_gdf['key'] == cand['key'])]\n",
    "            matched_edges.append(selected_edge)  \n",
    "            previous_edge = current_edge\n",
    "\n",
    "    matched_edges_gdf = pd.concat(matched_edges, ignore_index=True)\n",
    "    \n",
    "    #edges that don't contain a matched point:\n",
    "    matched_edges_vir = []\n",
    "    for (i1, k1), (i2, k2) in zip(best_candidate_path[:-1], best_candidate_path[1:]):\n",
    "        edge_list = edge_path[i2][k1][k2]\n",
    "    \n",
    "        # Keep all real edges (in the middle)\n",
    "        for (u, v, key, length) in edge_list:\n",
    "            if not isinstance(u, tuple) and not isinstance(v, tuple):\n",
    "                matched_edges_vir.append((u, v, key))\n",
    "    \n",
    "    # 2. Get geometries from edges_drive\n",
    "    # Step 1: Turn matched_edges_vir into a DataFrame directly\n",
    "    matched_edges_vir_df = pd.DataFrame(matched_edges_vir, columns=['u', 'v', 'key'])\n",
    "    \n",
    "    # Step 2: Merge with edges_drive to get full attributes (osmid, geometry, etc.)\n",
    "    matched_edges_vir_df = matched_edges_vir_df.merge(\n",
    "        edges_gdf,\n",
    "        on=['u', 'v', 'key'],\n",
    "        how='left'\n",
    "    )\n",
    "    matched_edges_vir_gdf = gpd.GeoDataFrame(matched_edges_vir_df, geometry='geometry', crs=edges_drive.crs)\n",
    "    \n",
    "    #concatenating the edges:\n",
    "    path_edges_gdf = pd.concat([matched_edges_gdf, matched_edges_vir_gdf])\n",
    "    return matched_points_gdf, path_edges_gdf\n",
    "\n",
    "###======================================== Functions used in Metric calculations ==========================================+\n",
    "\n",
    "# ------------------------- Function to remove extra parts of the begining and ending of the matched path -------------------+\n",
    "def trim_path_by_geometry(matched_path, best_candidate_path, all_candidate_points):\n",
    "    \"\"\"\n",
    "    Trim the first and last matched edges based on projected points,\n",
    "    and replace them only in the corresponding rows in the matched_path.\n",
    "    \n",
    "    Parameters:\n",
    "       - matched_path (GeoDataFrame): GeoDataFrame containing the matched edges of the path.\n",
    "       - best_candidate_path (list of tuple): List of (i, k) tuples representing the best candidate indices per GPS point.\n",
    "       - all_candidate_points (list of list of dict): All candidate points with their projected points and edge geometries.\n",
    "       \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with the first and last edges trimmed according to the projected points.    \n",
    "    \"\"\"\n",
    "\n",
    "    # Extract first and last candidate point info\n",
    "    first_i, first_k = best_candidate_path[0]\n",
    "    last_i, last_k = best_candidate_path[-1]\n",
    "\n",
    "    first_proj = all_candidate_points[first_i][first_k]['projected_point']\n",
    "    last_proj  = all_candidate_points[last_i][last_k]['projected_point']\n",
    "\n",
    "    first_geom = all_candidate_points[first_i][first_k]['edge_geometry']\n",
    "    last_geom  = all_candidate_points[last_i][last_k]['edge_geometry']\n",
    "\n",
    "    # Trim them\n",
    "    trimmed_first = substring(first_geom, first_geom.project(first_proj), first_geom.length)\n",
    "    trimmed_last  = substring(last_geom, 0, last_geom.project(last_proj))\n",
    "\n",
    "    # Copy the geometry list\n",
    "    trimmed_geoms = matched_path.geometry.tolist()\n",
    "\n",
    "    # Replace first match\n",
    "    for idx, g in enumerate(trimmed_geoms):\n",
    "        if g.equals(first_geom):\n",
    "            trimmed_geoms[idx] = trimmed_first\n",
    "            break\n",
    "\n",
    "    # Replace last match\n",
    "    for idx in reversed(range(len(trimmed_geoms))):\n",
    "        if trimmed_geoms[idx].equals(last_geom):\n",
    "        #if trimmed_geoms[idx].almost_equals(last_geom, decimal=6):    \n",
    "            trimmed_geoms[idx] = trimmed_last\n",
    "            break\n",
    "\n",
    "    return gpd.GeoDataFrame(geometry=trimmed_geoms, crs=matched_path.crs)\n",
    "    \n",
    "# ---------------------------- Trim when the whole path is a single edge ----------------------------+\n",
    "\n",
    "def trim_single_edge(matched_path, best_candidate_path, all_candidate_points):\n",
    "    \"\"\"\n",
    "    Trim a single edge path based on start and end projected points.\n",
    "\n",
    "    This function is useful when the entire matched path lies on one LineString edge.\n",
    "    It trims the edge geometry between the projected start and end points.\n",
    "\n",
    "    Parameters:\n",
    "       - matched_path (GeoDataFrame): GeoDataFrame containing the matched path geometry.\n",
    "       - best_candidate_path (list of tuple): List of (i, k) tuples indicating the best candidate indices.\n",
    "       - all_candidate_points (list of list of dict): All candidate points including projected points and edge geometries.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: A GeoDataFrame containing the trimmed geometry segment.    \n",
    "    \"\"\"\n",
    "\n",
    "    # Get start and end projections\n",
    "    first_i, first_k = best_candidate_path[0]\n",
    "    last_i, last_k = best_candidate_path[-1]\n",
    "\n",
    "    first_proj = all_candidate_points[first_i][first_k]['projected_point']\n",
    "    last_proj  = all_candidate_points[last_i][last_k]['projected_point']\n",
    "\n",
    "    edge_geom = all_candidate_points[first_i][first_k]['edge_geometry']\n",
    "\n",
    "    start_d = edge_geom.project(first_proj)\n",
    "    end_d   = edge_geom.project(last_proj)\n",
    "\n",
    "    # Ensure proper direction\n",
    "    start_d, end_d = min(start_d, end_d), max(start_d, end_d)\n",
    "\n",
    "    trimmed_geom = substring(edge_geom, start_d, end_d)\n",
    "\n",
    "    # Return as GeoDataFrame\n",
    "    return gpd.GeoDataFrame(geometry=[trimmed_geom], crs=matched_path.crs)\n",
    "###==================================================================================================> smart_trim_path\n",
    "def smart_trim_path(matched_path, best_candidate_path, all_candidate_points):\n",
    "    \"\"\"\n",
    "    Trim the matched path intelligently based on its structure.\n",
    "\n",
    "    If the matched path consists of a single edge, it calls `trim_single_edge`.\n",
    "    Otherwise, it calls `trim_path_by_geometry` for the general multi-edge case.\n",
    "\n",
    "    Parameters:\n",
    "       - matched_path (GeoDataFrame): GeoDataFrame of matched edges.\n",
    "       - best_candidate_path (list of tuple): List of best candidate indices (i, k).\n",
    "       - all_candidate_points (list of list of dict): Candidate points with projected points and edge geometries.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: Trimmed matched path as a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(matched_path) == 1:\n",
    "        # All points lie on the same edge\n",
    "        return trim_single_edge(matched_path, best_candidate_path, all_candidate_points)\n",
    "    else:\n",
    "        # General case\n",
    "        return trim_path_by_geometry(matched_path, best_candidate_path, all_candidate_points)\n",
    "\n",
    "###=====================================================================================> safe_linemerge() \n",
    "def safe_linemerge(geoms):\n",
    "    \"\"\"\n",
    "    Safely merge multiple LineString geometries into a single geometry.\n",
    "\n",
    "    Performs a unary union and attempts to merge resulting geometries.\n",
    "    Raises an error if the resulting geometry type is unexpected.\n",
    "\n",
    "    Parameter:\n",
    "        geoms (list): List of shapely LineString geometries.\n",
    "\n",
    "    Returns:\n",
    "        LineString or MultiLineString: Merged geometry.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the merged geometry type is not LineString or MultiLineString.\n",
    "    \"\"\"    \n",
    "    unioned = unary_union(geoms)\n",
    "    if isinstance(unioned, MultiLineString):\n",
    "        return linemerge(unioned)\n",
    "    elif isinstance(unioned, LineString):\n",
    "        return unioned\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected geometry type for merging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc641ed-09b0-4ed2-8ab4-bc7dfa13f05a",
   "metadata": {},
   "source": [
    "### Final ST_Matching function that calls all the other functions to run the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19d325-9c36-4f97-b707-333a9626085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ST_Matching(sample, network, edges_gdf, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform the full Spatial-Temporal (ST) Map Matching algorithm on a GPS trajectory sample.\n",
    "\n",
    "    The function executes the following steps:\n",
    "    1. Finds candidate road segments for each GPS point.\n",
    "    2. Computes observation probabilities for candidates.\n",
    "    3. Builds spatial and temporal score matrices.\n",
    "    4. Constructs the candidate graph.\n",
    "    5. Finds the best candidate path through the graph.\n",
    "    6. Extracts matched points and the final matched path.\n",
    "\n",
    "    Parameters:\n",
    "        sample (GeoDataFrame): GPS trajectory points with geometry and velocity.\n",
    "        network (networkx.DiGraph): Directed graph of the road network.\n",
    "        edges_gdf (GeoDataFrame): GeoDataFrame of road edges including speed limits.\n",
    "        verbose (bool): If True, print detailed processing information.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains the following keys:\n",
    "            - 'candidate_points': List of all candidate points per GPS observation.\n",
    "            - 'score_matrix': Nested spatial score matrix.\n",
    "            - 'edge_path': Nested dictionary of edge paths between candidates.\n",
    "            - 'temporal_matrix': Nested temporal similarity matrix.\n",
    "            - 'graph': NetworkX DiGraph representing candidate graph.\n",
    "            - 'best_path': List of nodes representing the best candidate path.\n",
    "            - 'matched_points': GeoDataFrame of matched candidate points.\n",
    "            - 'matched_path': GeoDataFrame of the final matched road path.\n",
    "    \"\"\"    \n",
    "    #finding the candidates\n",
    "    all_candidate_points = get_all_candidates(sample)\n",
    "    #adding the observation probability to the candidates\n",
    "    add_observation_probability(all_candidate_points)\n",
    "    #spatial score\n",
    "    score_matrix, edge_path = build_spatial_score_matrix(all_candidate_points, sample, network, verbose=verbose)\n",
    "    #temporal score\n",
    "    temporal_matrix = build_temporal_matrix(sample, edge_path, all_candidate_points, edges_gdf, verbose=verbose)\n",
    "    #build candidate graph\n",
    "    candidate_graph = build_candidate_graph(all_candidate_points, score_matrix, temporal_matrix)\n",
    "    #finding the best (longest) path\n",
    "    best_candidate_path = find_best_path(candidate_graph)\n",
    "    #getting the matched points and the final path \n",
    "    matched_points, matched_path = get_matched_points_and_edges(all_candidate_points, best_candidate_path, edge_path, edges_gdf, sample)\n",
    "    return {\n",
    "    'candidate_points': all_candidate_points,\n",
    "    'score_matrix': score_matrix,\n",
    "    'edge_path': edge_path,\n",
    "    'temporal_matrix': temporal_matrix,\n",
    "    'graph': candidate_graph,\n",
    "    'best_path': best_candidate_path,\n",
    "    'matched_points': matched_points,\n",
    "    'matched_path': matched_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41f73-efdf-42f5-ac35-f31b2bc07bf7",
   "metadata": {},
   "source": [
    "## 5. Run Map Matching\n",
    "\n",
    "This section runs the full ST-Matching algorithm on the prepared sample and network data.\n",
    "\n",
    "- It times the execution to monitor performance.\n",
    "- The results dictionary is unpacked into separate variables for easier access.\n",
    "- The key outputs include candidate points, score matrices, candidate graph, best path, and the final matched points and path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193fb96-b8fd-455f-852d-79603628fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.perf_counter()\n",
    "results = ST_Matching(sample, milan_drive, edges_drive)\n",
    "end = time.perf_counter()\n",
    "candidate_points = results['candidate_points']\n",
    "spatial_matrix = results['score_matrix']\n",
    "temporal_matrix = results['temporal_matrix']\n",
    "edge_path = results['edge_path']\n",
    "candidate_graph = results['graph']\n",
    "best_candidate_path = results['best_path']\n",
    "matched_points = results['matched_points']\n",
    "matched_path = results['matched_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8742718-06dc-494c-9dc5-858450aaa3c4",
   "metadata": {},
   "source": [
    "## 6. Computation of Metrics\n",
    "\n",
    "In this section, we compute key metrics to evaluate the performance and quality of the ST-Matching algorithm, including:\n",
    "\n",
    "- Trajectory sample identification  \n",
    "- Algorithm runtime  \n",
    "- Average number of candidate points per GPS sample  \n",
    "- Average spatial error between GPS points and matched points  \n",
    "- Edge and street revisit counts indicating loops in the matched path  \n",
    "- Length-based metrics comparing matched path length with GPS sample length  \n",
    "- Number of loops detected in the matched path  \n",
    "- Speed consistency metrics  \n",
    "- Path complexity ratio comparing path length to direct start-to-end distance  \n",
    "\n",
    "Finally, all computed metrics, key results, and intermediate data structures are consolidated into a summary dictionary for easy access, analysis, and reporting.\n",
    "This makes it possible later in a batch running operation to run the algorithm on a series of samples and keep the summaries for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82fa1b-4dd2-425e-b5d2-a845b63511b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. id of the trajectory sample\n",
    "traj_id = int(sample['Traj_ID'].iloc[0])\n",
    "\n",
    "# 2. Algorithm runtime\n",
    "runtime = end - start #runtime of the algorithm in seconds\n",
    "\n",
    "# 3. average number of candidate points per sample point\n",
    "number_of_candidate_points = 0\n",
    "for p in candidate_points:\n",
    "    number_of_candidate_points += len(p)  \n",
    "\n",
    "avg_cand_per_sample = number_of_candidate_points / len(sample)\n",
    "\n",
    "# 4. average distance between the sample points and their matched point\n",
    "matched_points_dist = [\n",
    "    candidate_points[i][k]['distance']\n",
    "    for (i, k) in best_candidate_path\n",
    "    ]\n",
    "\n",
    "average_distance = sum(matched_points_dist) / len(matched_points_dist)\n",
    "\n",
    "# 5. number of times edges are revisited in the path\n",
    "# (1) Revisited edges (exact u, v, key match)\n",
    "edge_revisit = len(matched_path) - matched_path[['u', 'v', 'key']].drop_duplicates().shape[0]\n",
    "# (2) Revisited streets (osmid match)\n",
    "street_revisit = len(matched_path) - matched_path['osmid'].nunique()\n",
    "\n",
    "# 6. Length metric\n",
    "     \n",
    "trimmed_path = smart_trim_path(matched_path, best_candidate_path, candidate_points)\n",
    "merged_trimmed = safe_linemerge(unary_union(trimmed_path.geometry))\n",
    "matched_path_length = merged_trimmed.length\n",
    "sample_aprx_length = sample['Delta_d'][1:].sum()\n",
    "length_metric = sample_aprx_length / matched_path_length\n",
    "\n",
    "# 7. number of loops in the path\n",
    "polygons = list(polygonize(merged_trimmed))\n",
    "number_of_loops = len(polygons)\n",
    "\n",
    "# 8. speed metric\n",
    "path_speed = matched_path_length / sample.Delta_t.iloc[1:].sum()\n",
    "sample_speed = sample.Delta_d.iloc[1:].sum() / sample.Delta_t.iloc[1:].sum()\n",
    "\n",
    "# 9. path complexity ratio ---> length of path / direct distance of first and last point\n",
    "direct_distance = sample['geometry'].iloc[0].distance(sample['geometry'].iloc[-1])\n",
    "complexity_ratio = matched_path_length / direct_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a78ab-7353-48fa-a7fe-dbe961abac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "    summary = {\n",
    "    'traj_id': traj_id,\n",
    "    'mean_proj_distance': average_distance,         # average distance between GPS and matched point\n",
    "    'path_length': matched_path_length,             # total matched path length\n",
    "    'sample_length': sample_aprx_length,            # sum of delta_d from sample\n",
    "    'length_metric': length_metric,                 # sample length / path length\n",
    "    'num_candidates': number_of_candidate_points,   # total number of candidate points\n",
    "    'avg_num_candidates': avg_cand_per_sample,      # avg number of candidates per GPS point\n",
    "    'path_speed': path_speed,                       # average path speed (m/s)\n",
    "    'sample_speed': sample_speed,                   # Sample speed calculated by delta_d and delta_t (m/s)\n",
    "    'runtime_seconds': runtime,                     # time taken\n",
    "    'revisited_edges': edge_revisit,                # number of times an edge is revisited in the path\n",
    "    'revisited_streets': street_revisit,            # number of times an street is revisited in different directions    \n",
    "    'num_loops': number_of_loops,                   # number of loops in the final matched path\n",
    "    'complexity_ratio': complexity_ratio,           # length of the path / direct distance between the first and last point\n",
    "    'buffer_type': 'fixed',                         # a fixed number based (50 meters) \n",
    "    'sigma_type': 'fixed',                          # a fixed experimental value (20)\n",
    "    'matched_points': matched_points,               # list of shapely Points (projected or final)\n",
    "    'matched_path': matched_path,                   # Dataframe of LineStrings\n",
    "    'trimmed_path': trimmed_path,                   # Dataframe of LineStrings with the beginning and ending of the path trimmed    \n",
    "    'candidate_points': candidate_points,           # List of candidate all points\n",
    "    'spatial_matrix': spatial_matrix,               # Spatial score matrix --> obs * trans\n",
    "    'temporal_matrix': temporal_matrix,             # Temporal score matrix\n",
    "    'edge_path': edge_path,                         # edges of the shortest paths\n",
    "    'candidate_graph': candidate_graph,             # the candidate DAG graph\n",
    "    'best_candidate_path': best_candidate_path      # a list of tuples of the selected candidate points from the graph\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75454b9f-1386-48ee-8813-53562ea35dc3",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "This section provides visual insights into the ST-Matching results:\n",
    "\n",
    "- **Candidate Graph:** An abstract Directed Acyclic Graph (DAG) view showing candidate points and the selected best path.\n",
    "- **Sample Points:** Original GPS trajectory points visualized in red.\n",
    "- **Matched Points:** Matched candidate points overlaid in green.\n",
    "- **Final Path:** The refined matched path displayed in blue.\n",
    "\n",
    "Interactive maps use CartoDB Positron tiles for a clean base map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cb6d7-4afc-47d4-9042-444492ee6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the candidate graph (DAG) and highlighting the selected best path and candidate points\n",
    "plot_abstract_candidate_graph(candidate_graph, start_layer=0, end_layer=16, best_path=best_candidate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2029e-bfae-4268-8c3c-bea9ba809ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the results on the map\n",
    "s = sample.explore(tiles=\"CartoDB positron\", color='red')\n",
    "mp = matched_points.explore(m=s, tiles='CartoDB positron', color='green')\n",
    "trimmed_path.explore(m=mp, tiles=\"CartoDB positron\", color='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
